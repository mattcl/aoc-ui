<script lang="ts">
  let year = 2023;

  let sourceCode = [
    {name: 'aoc-ci-bencher (CI pipeline defs)', repo: 'https://github.com/mattcl/aoc-ci-bencher' },
    {name: 'aoc-tools (CI helper)', repo: 'https://github.com/mattcl/aoc-tools' },
    {name: 'aoc-ui (frontend)', repo: 'https://github.com/mattcl/aoc-ui' },
    {name: 'aoc-web (backend)', repo: 'https://github.com/mattcl/aoc-web' },
    {name: 'hl-aoc-ui (kubernetes configs)', repo: 'https://github.com/mattcl/hl-aoc-web' },
  ];

</script>

<p><a href="https://adventofcode.com">Advent of Code</a> is an advent calendar
comprised of programming puzzles. This is an unofficial alternate comparison
mechanism that uses solution runtime time instead of the default
time-to-submission ranking.</p>

<p>These benchmarks are generated by a
<a href="http://ci.papercode.net:8080/teams/main/pipelines/aoc{year}">CI pipeline</a>
running on relatively dedicated hardware. Participant solutions are run against
a variety of valid inputs, with the goal of correcting for differences in input
complexity and speed individual hardware.</p>

<p>The benchmarks themselves are computed using
<a href="https://github.com/sharkdp/hyperfine">hyperfine</a>, which has the
effect of testing the entirety of program startup, reading the input from disk,
and computing the solution. As such, there is high variance for times less than
5 ms, as per the hyperfine documentation, as a not insignificant part of that is
shell startup time.</p>

<p>For 2023 and onward, more detailed results can be found in the
<a href="https://github.com/mattcl/aoc-benchmarks">benchmarks repo</a>.</p>

<h3>Source code:</h3>

<ul>
{#each sourceCode as s (s.name) }
  <li><a href="{s.repo}" target="_blank">{s.name}</li>
{/each}
</ul>
